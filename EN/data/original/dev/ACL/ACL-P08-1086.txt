Distributed Word Clustering for Large Scale Class-Based Language Modeling in Machine Translation .
In statistical language modeling , one technique to reduce the problematic effects of data sparsity is to partition the vocabulary into equivalence classes .
In this paper we investigate the effects of applying such a technique to higherorder n-gram models trained on large corpora .
We introduce a modification of the exchange clustering algorithm with improved efficiency for certain partially class-based models and a distributed version of this algorithm to efficiently obtain automatic word classifications for large vocabularies ( > 1 million words ) using such large training corpora ( > 30 billion tokens ) .
The resulting clusterings are then used in training partially class-based language models .
We show that combining them with word-based n-gram models in the log-linear model of a state-of-the-art statistical machine translation system leads to improvements in translation quality as indicated by the BLEU score .


