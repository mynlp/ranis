個人の音声を反映する映像エンタテインメントシステム
視聴者の顔をCGで再現し，CGキャラクタとして映画に登場させるFuture Cast System（FCS）を改良し，視聴者の声の特徴をそのキャラクタの台詞音声へ反映させ，キャラクタの顔と声の一致度を向上させて音声を出力するシステムを構築する．あらかじめ構築した話者データベースから視聴者の知覚的類似話者を選出し，その話者の台詞音声を視聴者のキャラクタに割り当て，短時間で台詞音声を映像と同期出力するシステムを提案する．知覚的類似話者は，個人性の知覚と関係があると報告されている8つの音響特徴量による距離の線形結合を用いて推定する．声優による60種類の声質の台詞音声データベースを用いた音声出力同期システムを構築し，視聴者のキャラクタの顔と選択された音声の一致度に関して5段階の主観評価を行った．登場者数と話者データベースの規模，および類似話者の許容度の関係を予備実験により調査し，実験条件にあてはめたところ，予想される許容度約51%に対して主観実験値において35%の許容が確認され，全体として予備実験で得られた予想値の68%が達成できた．
